# Applied Functional Analysis - Exercise sheet 2
Mateusz Dzitkowski, 249777

## Exercise 1
We have an equation
$$
\pi - x + \frac{1}{2}\sin\left(\frac{x}{2}\right) = 0
$$
for $x \in [0, 2\pi]$. We can rewrite it as 
$$
x = \pi + \frac{1}{2}\sin\left(\frac{x}{2}\right) = f(x),
$$
so our fixed point problem takes the form
$$
x_{n+1}=\pi + \frac{1}{2}\sin\left(\frac{x_n}{2}\right).
$$
Note that $f$ has values in $\left[\pi, \pi + \frac{1}{2}\right] \subset [0, 2\pi]$ on $[0, 2\pi]$, so we can write $f:[0, 2\pi] \rightarrow [0, 2\pi]$, just not a surjection. Now
$$
\left|f'(x)\right| = \left|\frac{1}{4}\cos(x)\right| \leq \frac{1}{4} = k \le 1,
$$
hence, by the theorem 2.1 from the lecture, the fixed point $x^*$ of $f$ exists, is unique, and $x^*\in[0, 2\pi]$.
Let's find the maximum of $g(x)=\left|f(x)-x\right|=\left|\pi+\frac{1}{2}\sin\left(\frac{x}{2}\right) - x\right|$ on $[0, 2\pi]$. We know that $h(x)=\pi+\frac{1}{2}\sin\left(\frac{x}{2}\right) - x$ is decreasing, so $g$ is decreasing on $[0, x^*]$. On $[x^*, 2\pi]$ the sign gets flipped and $g$ is increasing. So the maximum lies at $0$ or $2\pi$. We have
- $g(0) = |\pi + 0 - 0| = \pi$,
- $g(2\pi) = |\pi + 0 - 2\pi| = \pi$,
so $\max\limits_{0 \le x \le 2\pi} |x_1 - x_0|=\max\limits_{0 \le x \le 2\pi} g(x) = \pi$.
We want
$$
\frac{k^m}{1-k}|x_1 - x_0| \lt 0.01,
$$
plugging in the values we have
$$
\begin{aligned}
\frac{\left(\frac{1}{4}\right)^m}{\frac{3}{4}}\pi &\lt 0.01 \\
4^m &\gt \frac{400}{3}\pi \\
m &\gt log_4\left(\frac{400}{3}\pi\right) \approx 4.355,
\end{aligned}
$$
so you need at least $5$ iterations to guarantee $|x_m - x^*| \lt 0.01$.
Now, let $x_0=0$. We have
$$
\begin{aligned}
x_1 &= f(x_0) = \pi + \frac{1}{2}\sin\left(\frac{x_0}{2}\right) = \pi &\approx 3.14159,\\
x_2 &= \pi + \frac{1}{2} &\approx 3.64159,\\
x_3 &= \pi + \frac{1}{2}\cos\left(\frac{1}{4}\right) &\approx 3.62605,\\
x_4 &= \pi + \frac{1}{2}\cos\left(\frac{1}{4}\cos\left(\frac{1}{4}\right)\right) &\approx 3.62699,\\
x_5 &= \pi + \frac{1}{2}\cos\left(\frac{1}{4}\cos\left(\frac{1}{4}\cos\left(\frac{1}{4}\right)\right)\right) &\approx 3.62693,
\end{aligned}
$$
where the actual limit is $x^*\approx3.62694$, so we see that actually in less than $5$ iterations we were able to get an accuracy of $0.01$.
## Exercise 2
We have an equation
$$
x^2 - p = 0.
$$
The Newton's method gives us the following iteration scheme
$$
x_{n+1} = x_n - \frac{g(x_n)}{g'(x_n)},
$$
with $g(x) = x^2 - p$ which is a particular case of the fixed point iteration method. To see this, let $f(x) = x - \frac{g(x)}{g'(x)}$, we have $x_{n+1}=f(x_n)$.
Let's write $f(x)$ explicitly, we have
$$
f(x) = x - \frac{g(x)}{g'(x)} = x - \frac{x^2 - p}{2x} = \frac{1}{2}\left(x+\frac{p}{x}\right).
$$
Now let's prove that starting at any point $x_0 \gt 0$, the sequence generated by $x_{n+1} = f(x_n)$ will converge to $\sqrt{p}$.
Assume that $x_0 \gt 0$. We have
$$
x_{n+1}^2 - p = \frac{1}{4}\left(x_n+\frac{p}{x_n}\right)^2 - p = \frac{1}{4}x_n^2 + \frac{1}{2}p + \frac{1}{4}\frac{p^2}{x_n^2} - p = \frac{1}{4}\left(x_n - \frac{p}{x_n}\right)^2 \gt 0,
$$
hence $x_n \gt \sqrt{p}$ for all $n>0$. Also
$$
x_n \gt \sqrt{p} \gt \frac{p}{x_n}.
$$
Now we can show that $x_n$ is decreasing for all $n \gt 0$. We have
$$
x_{n+1} - x_n = \frac{1}{2}\left(x_n + \frac{p}{x_n}\right) - x_n = \frac{1}{2}\left(\frac{p}{x_n} - x_n\right) \lt 0,
$$
which proves that $x_n$ is, in fact, decreasing for $n \gt 0$. From this, and from the fact that $x_n \gt \sqrt{p}$, we know that $x_n$ has a limit. Let's compute it. We have
$$
\begin{aligned}
x^* &= \frac{1}{2}\left(x^* + \frac{p}{x^*}\right)\\
\frac{1}{2}x^* &= \frac{1}{2}\frac{p}{x^*}\\
x^* &= \frac{p}{x^*}\\
(x^*)^2 &= p,
\end{aligned}
$$
and, since $x_n \gt 0$, we have $x^* = \sqrt{p}$. If, on the other hand, we assumed $x_0 \lt 0$, it would be obvious from the definition of $x_n$, that $x_n \lt 0$ for every $n$, which would prevent the sequence from converging to $\sqrt{p}$.
So the interval that guarantees convergence to $\sqrt{p}$ is $(0, \infty)$.

Let us use the contraction condition to determine the interval that guarantees convergence to $\sqrt{p}$. We want
$$
|f'(x)| = \left|\frac{1}{2}\left(1 - \frac{p}{x^2}\right)\right| \lt 1.
$$
We have three cases there, let's go over them one by one:
- case $x \gt \sqrt{p}$:
	$$
	\begin{aligned}
	\frac{1}{2}\left(1 - \frac{p}{x^2}\right) &\lt 1 \\
	1 - \frac{p}{x^2} &\lt 2 \\
	-\frac{p}{x^2} &\lt 1 \\
	-p &\lt x^2,
	\end{aligned}
	$$
	and that is true always, because $p$ is positive, so from this case we get $x \in (\sqrt{p}, \infty)$,
- case $x = \sqrt{p}$:
	we get $0 \lt 1$, also, we're already at the limit, so $x \in \{\sqrt{p}\}$,
- case $x \gt \sqrt{p}$:
	$$
	\begin{aligned}
	\frac{1}{2}\left(\frac{p}{x^2} - 1\right) &\lt 1 \\
	\frac{p}{x^2} - 1 &\lt 2 \\
	\frac{p}{x^2} &\lt 3 \\
	x &\gt \sqrt{\frac{p}{3}}
	\end{aligned}
	$$
	so $x \in \left(\sqrt{\frac{p}{3}}, \sqrt{p}\right)$.
Combining these three cases we get the condition $x \in \left(\sqrt{\frac{p}{3}}, \infty\right)$. So the method using the contraction of $f$ gave us a worse result than the direct analysis of the sequence.
## Exercise 3
We consider the following integral equation
$$
f(x) = x + \frac{1}{4}\int_0^\frac{\pi}{2}f(y)\cos(x)dy.
$$
Relating this to the equation from the lecture we have $g(x) = x$, $k(x, y) = \cos(x)$, and $\mu = \frac{1}{4}$. Furthermore, $|k(x,y)| \leq 1 = c$, so
$$
\frac{1}{4} = \mu \lt \frac{1}{c(b-a)} = \frac{1}{\frac{\pi}{2}} = \frac{2}{\pi} \lt \frac{2}{3}.
$$
This proves that the functional $T$ defined by 
$$
T(f)(x) = x + \frac{1}{4}\int_0^\frac{\pi}{2}f(y)\cos(x)dy
$$
is a contraction, and hence, by the Banach's FPT, has a unique fixed point in $C\left[0, \frac{\pi}{2}\right]$.
Let's rewrite the operator $T$ as 
$$
T(f)(x) = x + \frac{1}{4}\cos(x)\int_0^\frac{\pi}{2}f(y)dy.
$$
We can make this into a function sequence in the following way
$$
f_{n+1} = T(f_n).
$$
Let's take $f_0(x)=x$. We can write a few terms of the sequence by applying $T$:
$$
\begin{aligned}
f_0(x) &= x\\
f_1(x) &= x + \frac{1}{4}\cos(x)\int_0^\frac{\pi}{2}xdx = x + \frac{1}{4}\cos(x)\cdot\frac{\pi^2}{8}\\
f_2(x) &= x + \frac{1}{4}\cos(x)\cdot\frac{5\pi^2}{32}\\
f_3(x) &= x + \frac{1}{4}\cos(x)\cdot\frac{21\pi^2}{128}.
\end{aligned}
$$
We can see that the functions $f_n$ can be characterised by just the one number, that being the integral of the previous one in the sequence, $f_{n-1}$. We can write
$$
\begin{aligned}
f_C(x) &= x + \frac{C}{4}\cos(x),\\
C_{n+1} &= \int_0^\frac{\pi}{2}f_{C_n}(x)dx = \int_0^\frac{\pi}{2}\left(x + \frac{C_n}{4}\cos(x)\right)dx = \frac{\pi^2}{8} + \frac{C_n}{4},
\end{aligned}
$$
with $C_0=0$. Omitting the formal proof of the convergence of $C_n$, we can find it by looking for solutions to
$$
C = \frac{\pi^2}{8} + \frac{C}{4},
$$
which yields $C=\frac{\pi^2}{6}$, which, if we plug that in, in fact gives us $T(f_C) = f_C$.
## Exercise 4
We are presented with an initial value problem:
$$
\begin{aligned}
x'(t) &= 2x(t)+2\\
x(0) &= 0
\end{aligned}.
$$
Solving this problem is trivial, we obtain $x(t) = e^{2t} - 1$.
The successive approximation scheme looks as follows
$$
x_{n+1}(t) = x(0) = \int_0^tx'_n(s)ds = \int_0^t\left(2x_n(s) + 2\right)ds = 2t + 2\int_0^tx_n(s)ds.
$$
Let us also choose $x_0(t)=0$. We will prove that $x_n(t) = \sum_{m=1}^n\frac{(2t)^m}{m!}$. To that end, let's check that equality for an initial $n=0$. We have
$$
x_0(t) = 0 = \sum_{m=1}^0\frac{(2t)^m}{m!}.
$$
Now let's assume that this holds for $n$, and look at $n+1$. We have
$$
\begin{aligned}
x_{n+1}(t) &= 2t + 2\int_0^tx_n(s)ds \\ 
&= 2t + 2\int_0^t\sum_{m=1}^n\frac{(2s)^m}{m!}ds \\
&= 2t + \sum_{m=1}^n\int_0^t\frac{(2s)^m}{m!}2ds \\
&= 2t + \sum_{m=1}^n\int_0^{2t}\frac{u^m}{m!}du  \\ 
&= 2t + \sum_{m=1}^n\frac{(2t)^{m+1}}{(m+1)!} \\ 
&= \frac{(2t)^1}{1!} + \sum_{m=2}^{n+1}\frac{(2t)^m}{m!} \\
&= \sum_{m=1}^{n+1}\frac{(2t)^m}{m!}.
\end{aligned}
$$
We can also write $x_n(t) = \sum_{m=0}^n\frac{(2t)^m}{m!} - 1$. It is now trivial to note that
$$
\lim\limits_{n \rightarrow \infty} x_n(t) = \sum_{m=1}^\infty\frac{(2t)^m}{m!} - 1 = e^{2t} - 1,
$$
which we obtained from solving the equation analytically.
